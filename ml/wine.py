# -*- coding: utf-8 -*-
"""Proyecto 1 - Modelo 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tU9TWEZpppte3JQK7Q_F7Hqwl74a7RMG

# Analisis del problema
 Se necesita predecir, a partir de una serie de características fisicoquímicas del vino, la calidad del mismo en una escala numérica. Estas características incluyen propiedades como la acidez fija, el nivel de alcohol, el pH, el contenido de azúcar residual, entre otras, que se obtienen a través de pruebas de laboratorio. El objetivo es entrenar un modelo de machine learning que pueda aprender patrones en los datos y, con base en las características de un vino nuevo, predecir su calidad de manera automática.

En este contexto, "clasificar la calidad del vino" significa asignar una etiqueta o clase de calidad a cada vino basado en sus atributos. Esta calidad es usualmente representada como una variable categórica ordinal (por ejemplo, del 3 al 8 en nuestro dataset), donde un número mayor indica una mejor calidad. La tarea de clasificación busca minimizar los errores al asignar incorrectamente la calidad, identificando correctamente tanto los vinos de alta como de baja calidad.

# Entendimiento de los datos
El dataset contiene varias características fisicoquímicas del vino que permiten predecir su calidad. A continuación, se describen las principales columnas:

fixed acidity (float): Nivel de acidez fija que afecta el sabor del vino.

volatile acidity (float): Ácidos que se evaporan, niveles altos indican menor calidad.

citric acid (float): Añade frescura al vino, influyendo en la percepción de calidad.

residual sugar (float): Cantidad de azúcar residual tras la fermentación.

chlorides (float): Contenido de sal; niveles altos pueden ser un indicador negativo.

free sulfur dioxide (float) y total sulfur dioxide (float): Agentes conservantes que, en exceso, pueden afectar el aroma y sabor.

density (float): Relacionada con el contenido de alcohol y azúcar.
pH (float): Indica la acidez o alcalinidad del vino.

sulphates (float): Conservante que influye en la estabilidad y el sabor.

alcohol (float): Nivel de alcohol, impacta la calidad percibida.

type (categorical): Tipo de vino (tinto o blanco).

quality (integer): Variable objetivo, mide la calidad del vino en una escala de 3 a 8.

Las características son principalmente numéricas, y la variable de tipo se convierte en una variable categórica para su uso en el modelo.
"""

# Importar las librerías necesarias
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Cargar el dataset
file_path = '../datasets/winequalityN.csv'
wine_data = pd.read_csv(file_path)

# Separar las características de la variable objetivo
X = wine_data.drop(columns=['quality'])
y = wine_data['quality']

# Convertir la columna 'type' (vino blanco o tinto) a variables dummies
X = pd.get_dummies(X, columns=['type'], drop_first=True)

# Imputar los valores faltantes usando la media de cada columna
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Escalar los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_imputed)

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

"""# Modelo"""

# Crear y entrenar el modelo Random Forest optimizado
rf_model_optimized = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=5, min_samples_leaf=2, random_state=42, class_weight='balanced' )
rf_model_optimized.fit(X_train, y_train)

# Predecir con los datos de prueba
y_pred_rf_optimized = rf_model_optimized.predict(X_test)
print(y_pred_rf_optimized)

# Generar el informe de clasificación
classification_report_rf_optimized = classification_report(y_test, y_pred_rf_optimized)
print(classification_report_rf_optimized)

"""# Evaluaciones"""

import matplotlib.pyplot as plt

# Obtener la distribución de la variable objetivo (quality)
class_distribution = wine_data['quality'].value_counts().sort_index()

# Crear el diagrama de barras para mostrar la distribución de clases
plt.figure(figsize=(8, 6))
plt.bar(class_distribution.index, class_distribution.values, color='skyblue')
plt.xlabel('Clase de Calidad del Vino')
plt.ylabel('Cantidad de Ejemplares')
plt.title('Distribución de Clases en el Conjunto de Datos de Calidad del Vino')
plt.xticks(class_distribution.index)
plt.show()

y_pred_test = rf_model_optimized.predict(X_test)
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np

# Obtener la matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred_test)

# Función para calcular precisión, sensibilidad y especificidad
def calculate_metrics(conf_matrix):
    # Verdaderos positivos, falsos positivos, falsos negativos y verdaderos negativos
    tp = np.diag(conf_matrix)
    fp = conf_matrix.sum(axis=0) - tp
    fn = conf_matrix.sum(axis=1) - tp
    tn = conf_matrix.sum() - (fp + fn + tp)

    # Precisión global
    accuracy = (tp.sum() / conf_matrix.sum())

    # Sensibilidad (recall) por clase
    sensitivity = tp / (tp + fn)

    # Especificidad por clase
    specificity = tn / (tn + fp)

    return accuracy, sensitivity, specificity

# Calcular precisión global, sensibilidad y especificidad
accuracy, sensitivity, specificity = calculate_metrics(conf_matrix)

# Mostrar resultados
print("Precisión global:", accuracy)
print("Sensibilidad (recall) por clase:", sensitivity)
print("Especificidad por clase:", specificity)

# También puedes mostrar el informe de clasificación
print("\nInforme de clasificación:\n", classification_report(y_test, y_pred_test))

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

# Crear el diagrama de la matriz de confusión para validar los resultados del modelo
fig, ax = plt.subplots(figsize=(8, 6))
ConfusionMatrixDisplay(confusion_matrix=conf_matrix).plot(ax=ax)
plt.title("Matriz de Confusión - Validación de Resultados del Modelo")
plt.show()

"""# Resultados
El modelo de clasificación Random Forest logró una **precisión global del 67%**, lo que indica un rendimiento aceptable en general. La matriz de confusión muestra que el modelo clasifica correctamente las clases más comunes, como las calidades **5** y **6**, con un **recall** (sensibilidad) del 71% y 77%, respectivamente. Sin embargo, tiene dificultades para identificar las clases menos representadas, como la calidad **3**, que no fue predicha correctamente, y la calidad **4**, que presenta un **recall** del 14%. Además, el modelo confunde las clases intermedias (5 y 6) con las clases adyacentes, sugiriendo que hay margen de mejora en la diferenciación entre clases cercanas en términos de calidad. Aunque los resultados son razonables para las clases mayoritarias, se podrían realizar ajustes adicionales, como balancear las clases o afinar los hiperparámetros, para mejorar el rendimiento en las clases minoritarias.
"""

# Guardar el modelo
import joblib

joblib.dump(rf_model_optimized, '../models/wine.pkl')
print("Modelo guardado correctamente en 'wine.pkl'")